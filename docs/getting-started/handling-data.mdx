---
title: Handling Data
description: Learn how to handle server-side data in Dara applications using ServerVariable and work with large tabular data
boost: 1.5
---

This page will introduce you to handling data in Dara applications, covering both server-side data management and working with tabular data.

## Understanding Data in Dara

Dara provides different approaches for handling data depending on where the data originates and how it's managed:

- **Client State**: Use `Variable`s for ephemeral UI state
- **Client State with Persistence**: Use `Variable` with a `store` for UI state that needs persistence or collaboration (covered in [Persistence and Collaboration](../advanced/persistence-and-collaboration.mdx))
- **Server-Side Data**: Use `ServerVariable` for data that originates and is managed on the server
- **Computed Data**: Use `DerivedVariable` for data derived from other variables

## Server-Side Data with ServerVariable

`ServerVariable` represents **synchronized server state** - data that originates and is managed on the server, with clients receiving reactive updates when the data changes but not sending the actual data to the client.
This is notably different from `Variable`s with `BackendStore`, which represents client state that happens to be persisted on the server but it still synced in its entirety with the client.

### Key Characteristics

- **Server as Source of Truth**: Data originates from and is managed by the server
- **Reactive Updates**: Clients automatically receive updates when server data changes
- **Non-Serializable Support**: Can store any Python object, including ML models, database connections, etc.
- **Automatic Synchronization**: Changes propagate to all connected clients via WebSocket

### Basic Usage

```python
import pandas as pd
from dara.core import ServerVariable
from dara.components import Table, Text, Stack

# Basic DataFrame storage
dataset = ServerVariable(pd.DataFrame({
    'experiment': ['A', 'B', 'C'],
    'accuracy': [0.85, 0.92, 0.78],
    'samples': [1000, 1500, 800]
}))

# Non-serializable data (ML model)
from sklearn.ensemble import RandomForestClassifier
trained_model = ServerVariable(
    RandomForestClassifier().fit(X_train, y_train),
    scope='global'
)

# Tabular data display
page_content = Stack(
    Text('Experiment Results'),
    Table(data=dataset)  # Automatically handles filtering/pagination
)
```

### Scope Management

ServerVariable supports two scopes:

- **`global`**: Data shared across all users (default, also supports setting an initial value)
- **`user`**: Separate data per user, useful for e.g. personalized datasets or user-specific analysis results

```python
# Global data - shared across all users
global_dataset = ServerVariable(
    pd.read_csv('shared_results.csv'),
    scope='global'
)

# User-specific data - separate per user
user_analysis = ServerVariable(
    scope='user',
    backend=UserAnalysisBackend()
)
```

### Custom Backends

For advanced use cases, you can implement custom backends to integrate with databases, APIs, or other data sources:

```python
from dara.core.interactivity.server_variable import ServerBackend
from typing import Optional, Tuple, Union
import asyncpg

class DatabaseBackend(ServerBackend):
    def __init__(self, connection_string: str):
        super().__init__(scope='global')
        self.connection_string = connection_string
        self._sequence_numbers = {}

    async def read(self, key: str):
        # Read full dataset
        conn = await asyncpg.connect(self.connection_string)
        try:
            rows = await conn.fetch("SELECT * FROM experiments")
            return pd.DataFrame(rows)
        finally:
            await conn.close()

    async def write(self, key: str, value):
        # Handle data updates
        # Implementation depends on your use case
        pass

    async def get_sequence_number(self, key: str) -> int:
        # Track data version for synchronization
        return self._sequence_numbers.get(key, 0)

# Use custom backend
database_data = ServerVariable(backend=DatabaseBackend("postgresql://..."))
```

## Working with Tabular Data

Tabular data handling in Dara is optimized for performance with large datasets through built-in filtering, pagination, and lazy loading.

### Table Component Integration

The `Table` component automatically integrates with both `ServerVariable` and `DerivedVariable` to provide efficient data display:

```python
from dara.core import ServerVariable, DerivedVariable, Variable
from dara.components import Table, Stack, Select, Item

# Large dataset stored on server
large_dataset = ServerVariable(pd.read_csv('large_file.csv'))

# Filtered view based on user selection
category_filter = Variable('all')

def filter_by_category(data, category):
    if category == 'all':
        return data
    return data[data['category'] == category]

filtered_data = DerivedVariable(
    filter_by_category,
    variables=[large_dataset, category_filter]
)

page_content = Stack(
    Select(
        value=category_filter,
        items=[
            Item(label='All Categories', value='all'),
            Item(label='Category A', value='A'),
            Item(label='Category B', value='B')
        ]
    ),
    # Table automatically handles pagination and filtering
    # Use the entire dataset
    Table(data=large_dataset),
    # Or the filtered one
    Table(data=filtered_data)
)
```

### Custom ServerVariable filtering

Server variables handle filtering and pagination via their `backend` implementation and its `read_filtered` method. The default `MemoryBackend` stores the data in memory and implements `DataFrame` filtering.
This means that with the default backend, the only type of tabular data supported is a `DataFrame`.

For advanced tabular data scenarios, you can implement custom backends with customized `read_filtered` methods. The example below shows how one could implement a backend that stores the data in a database,
and translates the filtering and pagination queries into SQL queries that retrieve a slice of the DB data as a `DataFrame`.

```python
from dara.core.interactivity.server_variable import ServerBackend
from dara.core.interactivity.filtering import FilterQuery, Pagination
from typing import Optional, Tuple
import pandas as pd
import asyncpg

class DatabaseBackend(ServerBackend):
    def __init__(self, connection_string: str):
        super().__init__(scope='global')
        self.connection_string = connection_string

    async def read(self, key: str):
        # Read full dataset (used for programmatic non-tabular access)
        conn = await asyncpg.connect(self.connection_string)
        try:
            rows = await conn.fetch("SELECT * FROM large_table")
            return pd.DataFrame(rows)
        finally:
            await conn.close()

    async def read_filtered(
        self,
        key: str,
        filters: Optional[FilterQuery] = None,
        pagination: Optional[Pagination] = None
    ) -> Tuple[Optional[pd.DataFrame], int]:
        """
        Optimized filtering at the database level for better performance.
        Translates the filters and pagination into SQL queries that retrieve a slice of the DB data as a `DataFrame`.
        """
        conn = await asyncpg.connect(self.connection_string)
        try:
            # Build SQL query from filters
            where_clause = self._build_where_clause(filters)
            count_query = f"SELECT COUNT(*) FROM large_table {where_clause}"
            total_count = await conn.fetchval(count_query)

            # Apply pagination
            limit_clause = ""
            if pagination:
                offset = pagination.offset or 0
                limit = pagination.limit or 50
                limit_clause = f"LIMIT {limit} OFFSET {offset}"

            # Fetch filtered data
            data_query = f"SELECT * FROM large_table {where_clause} {limit_clause}"
            rows = await conn.fetch(data_query)

            return pd.DataFrame(rows), total_count

        finally:
            await conn.close()

    def _build_where_clause(self, filters: Optional[FilterQuery]) -> str:
        # Convert Dara filters to SQL WHERE clause
        # Implementation depends on your filter requirements
        if not filters:
            return ""
        # ... filter conversion logic
        return "WHERE ..."

# Use optimized backend
optimized_data = ServerVariable(backend=DatabaseBackend("postgresql://..."))

# Table will use read_filtered for efficient server-side filtering
efficient_table = Table(data=optimized_data)
```

### Custom Filter Resolvers with DerivedVariable

Similar to `ServerVariable`, `DerivedVariable`s also support a default `DataFrame` filtering for tabular data. This means that by default, to use a `DerivedVariable` with e.g. a `Table` component,
its function must return a `DataFrame` or `None`. This can be customized by providing a `filter_resolver` function. It will be called with the result of the main `DerivedVariable` function,
as well as filters and pagination. The function should return a `DataFrame` and total count.

The example below shows how to use a custom filter resolver to filter a `DerivedVariable` that returns a `DataFrame` with a remote API.

```python
from dara.core import DerivedVariable, Variable
from dara.core.interactivity.filtering import FilterQuery, Pagination
import httpx

# API-based data filtering
async def api_filter_resolver(
    endpoint_url: str,
    filters: Optional[FilterQuery] = None,
    pagination: Optional[Pagination] = None
) -> Tuple[pd.DataFrame, int]:
    """
    Custom resolver that queries a remote API with filters
    """
    async with httpx.AsyncClient() as client:
        # translate filters and pagination into API query params
        params = {
            'filters': filters.dict() if filters else {},
            'offset': pagination.offset if pagination else 0,
            'limit': pagination.limit if pagination else 50,
        }

        response = await client.get(endpoint_url, params=params)
        data = response.json()

        return pd.DataFrame(data['results']), data['total_count']

# Parameters for API query
api_params = Variable({'dataset': 'experiments', 'version': 'latest'})

def build_api_endpoint(params):
    return f"https://api.example.com/data/{params['dataset']}/{params['version']}"

# DerivedVariable with custom filtering
api_data = DerivedVariable(
    build_api_endpoint,
    variables=[api_params],
    filter_resolver=api_filter_resolver
)

# Table automatically uses the custom filter resolver
api_table = Table(
    data=api_data,
    columns=['experiment_id', 'accuracy', 'timestamp']
)
```

### Performance Best Practices

1. **Use ServerVariable or DerivedVariable for Large Datasets**: Store datasets on the server rather than passing them directly into a `Table` component to offload the filtering and pagination logic to the backend
2. **Implement custom backends or filter_resolver for remote data**: For remote data, it's more efficient to retrieve only a slice of the data than to retrieve the entire dataset and filter it in-memory

## Next Steps

You've learned how to handle both server-side data and tabular data in Dara applications. The next section will cover how to organize these data-driven components into complete application layouts and navigation structures.
